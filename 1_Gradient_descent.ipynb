{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ-xu9_BJycN"
      },
      "source": [
        "# 使用`openai api`來微調分類器\n",
        "\n",
        "使用`ada`來微調分類器，並且使用`ada`來預測分類結果。預測一個句子的分類結果，並且計算出分類的機率。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 安裝命令列提示下的`openai`套件"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZhCM4pyKAcG",
        "outputId": "389047e0-2028-408c-97dc-cc9f28224eab"
      },
      "outputs": [],
      "source": [
        "!pip install openai # 安裝 OpenAI 的 Python 套件"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 安裝需要的資料集\n",
        "\n",
        "這邊使用sklearn中的20newsgroups資料集，這個資料集是一個新聞分類的資料集，共有20個類別，每個類別有數百篇新聞，這邊我們只使用其中的4個類別，並且只取出每篇新聞的內容，並且將其轉換成一個list，每個list中的元素都是一個新聞的內容。使用baseball和hockey兩個新聞類別，並且將其轉換成一個list，每個list中的元素都是一個新聞的內容。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Uaao1d7UJycO"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "import openai\n",
        "\n",
        "categories = ['rec.sport.baseball', 'rec.sport.hockey']\n",
        "sports_dataset = fetch_20newsgroups(subset='train', shuffle=True, random_state=42, categories=categories)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TezA5sy2JycP"
      },
      "source": [
        " ### 查看資料\n",
        " 先看資料長什麼樣子，這邊我們只看第1筆資料。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2F9f3eiJycP",
        "outputId": "274ed56d-ef59-489f-b5d0-9f5d50414553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From: gld@cunixb.cc.columbia.edu (Gary L Dare)\n",
            "Subject: Re: Flames Truly Brutal in Loss\n",
            "Nntp-Posting-Host: cunixb.cc.columbia.edu\n",
            "Reply-To: gld@cunixb.cc.columbia.edu (Gary L Dare)\n",
            "Organization: PhDs In The Hall\n",
            "Distribution: na\n",
            "Lines: 13\n",
            "\n",
            "\n",
            "This game would have been great as part of a double-header on ABC or\n",
            "ESPN; the league would have been able to push back-to-back wins by\n",
            "Le Magnifique and The Great One.  Unfortunately, the only network\n",
            "that would have done that was SCA, seen in few areas and hard to\n",
            "justify as a pay channel. )-;\n",
            "\n",
            "gld\n",
            "--\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~ Je me souviens ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "Gary L. Dare\n",
            "> gld@columbia.EDU \t\t\tGO  Winnipeg Jets  GO!!!\n",
            "> gld@cunixc.BITNET\t\t\tSelanne + Domi ==> Stanley\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(sports_dataset['data'][1])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 查看是什麼類別"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qY40JZ8LJycP",
        "outputId": "b5d55ab0-c6aa-46ea-bbb1-f23560f63c7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'rec.sport.baseball'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sports_dataset.target_names[sports_dataset['target'][0]]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 印出每個類別的長度\n",
        "我們要用這個類別的文字資料來做文字分類"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhiGIwtEJycP",
        "outputId": "12f68d10-1a0b-455a-f111-400541e13424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total examples: 1197, Baseball examples: 597, Hockey examples: 600\n"
          ]
        }
      ],
      "source": [
        "len_all, len_baseball, len_hockey = len(sports_dataset.data), len([e for e in sports_dataset.target if e == 0]), len([e for e in sports_dataset.target if e == 1])\n",
        "print(f\"Total examples: {len_all}, Baseball examples: {len_baseball}, Hockey examples: {len_hockey}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TjCo9CLgJycQ"
      },
      "source": [
        "### 資料準備\n",
        "將資料集轉換為一個`pandas` `dataframe`，其中包含一個用於提示和完成的列。提示中包含了郵件列表中的電子郵件，而完成則是運動的名稱，可以是曲棍球或棒球。為了示範目的和微調速度，我們僅選取了300個例子。在實際應用中，例子越多，性能越好。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z2nOkAhlJycQ",
        "outputId": "690ee09a-d9b5-4724-eb8b-e0d0f47b601b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: dougb@comm.mot.com (Doug Bank)\\nSubject:...</td>\n",
              "      <td>baseball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: gld@cunixb.cc.columbia.edu (Gary L Dare)...</td>\n",
              "      <td>hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: rudy@netcom.com (Rudy Wade)\\nSubject: Re...</td>\n",
              "      <td>baseball</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: monack@helium.gas.uug.arizona.edu (david...</td>\n",
              "      <td>hockey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Subject: Let it be Known\\nFrom: &lt;ISSBTL@BYUVM....</td>\n",
              "      <td>baseball</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              prompt completion\n",
              "0  From: dougb@comm.mot.com (Doug Bank)\\nSubject:...   baseball\n",
              "1  From: gld@cunixb.cc.columbia.edu (Gary L Dare)...     hockey\n",
              "2  From: rudy@netcom.com (Rudy Wade)\\nSubject: Re...   baseball\n",
              "3  From: monack@helium.gas.uug.arizona.edu (david...     hockey\n",
              "4  Subject: Let it be Known\\nFrom: <ISSBTL@BYUVM....   baseball"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "labels = [sports_dataset.target_names[x].split('.')[-1] for x in sports_dataset['target']]\n",
        "texts = [text.strip() for text in sports_dataset['data']]\n",
        "df = pd.DataFrame(zip(texts, labels), columns = ['prompt','completion']) #[:300]\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sS3f6L_zJycQ"
      },
      "source": [
        "\"baseball\"和\"hockey\"都是單一tokens。這邊規定要轉成`jsonl`格式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "huoQnRK-JycQ"
      },
      "outputs": [],
      "source": [
        "df.to_json(\"sport2.jsonl\", orient='records', lines=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lWJblmmoJycQ"
      },
      "source": [
        "### 使用`openai api`來上傳資料\n",
        "使用一個資料準備工具，在微調之前對資料集進行一些改進。在啟動工具之前，我們會更新 OpenAI 函式庫，以確保使用最新的資料準備工具。我們還額外指定了\"-q\"參數，自動接受所有建議。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs0v6pGiJycQ",
        "outputId": "ff4a09d0-a778-4001-bbc3-49ae00bf6a2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (0.27.6)\n",
            "Requirement already satisfied: aiohttp in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from openai) (3.8.3)\n",
            "Requirement already satisfied: requests>=2.20 in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from openai) (2.28.1)\n",
            "Requirement already satisfied: tqdm in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.14)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from aiohttp->openai) (22.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/joshhu/anaconda3/envs/gpt3/lib/python3.10/site-packages (from aiohttp->openai) (1.8.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISLtYmgrJycQ",
        "outputId": "b02ea6c6-1a00-416d-fa1b-8c068426ac99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your file contains 1197 prompt-completion pairs\n",
            "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
            "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
            "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
            "- There are 11 examples that are very long. These are rows: [134, 200, 281, 320, 404, 595, 704, 838, 1113, 1139, 1174]\n",
            "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Recommended] Remove 11 long examples [Y/n]: Y\n",
            "- [Recommended] Add a suffix separator `\\n\\n###\\n\\n` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified files to `sport2_prepared_train (1).jsonl` and `sport2_prepared_valid (1).jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"sport2_prepared_train (1).jsonl\" -v \"sport2_prepared_valid (1).jsonl\" --compute_classification_metrics --classification_positive_class \" baseball\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt.\n",
            "Once your model starts training, it'll approximately take 30.8 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ],
      "source": [
        "!openai tools fine_tunes.prepare_data -f sport2.jsonl -q"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aWJ2IYnQJycR"
      },
      "source": [
        "將數資料集分為訓練集和驗證集。\n",
        "\n",
        "要在提示和完成之間加上一個後綴，告訴模型輸入文字已經結束，現在需要預測類別。由於我們在每個例子中使用相同的分隔符號，模型能夠學會它應該在分隔符之後預測棒球或曲棍球。\n",
        "\n",
        "在完成部分加上空格，因為大多數單詞token都帶有空格前綴。\n",
        "\n",
        "該工具還識別到這可能是一個分類任務，建議將數據集分為訓練集和驗證集。這將使我們能夠輕鬆地測量對新數據的預期性能"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rP2CHEuyJycR"
      },
      "source": [
        "### 開始微調臨型\n",
        "該工具建議我們運行以下命令來訓練數據集。由於這是一個分類任務，我們希望知道在提供的驗證集上的泛化性能如何，以滿足我們的分類使用情境。該工具建議添加 `--compute_classification_metrics` `--classification_positive_class \"baseball\"` 來計算分類指標。\n",
        "\n",
        "我們可以直接從命令行工具中複製建議的命令。我們特別添加了 `-m ada`，以微調一個更經濟、更快速的 ada 模型，在分類使用情境中通常與速度較慢、更昂貴的模型在性能上相當。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9vSvcwaJycR",
        "outputId": "229eedfd-01ad-4019-9e38-4ef5ba3cfe2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found potentially duplicated files with name 'sport2_prepared_train.jsonl', purpose 'fine-tune' and size 1519036 bytes\n",
            "file-iLrr4IHweg2sCCRcYNcBbMtg\n",
            "file-L3fySLiYqXhYDjWEfBfuTmmI\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: ^C\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!openai -k \"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\" api fine_tunes.create -t \"sport2_prepared_train.jsonl\" -v \"sport2_prepared_valid.jsonl\" --compute_classification_metrics --classification_positive_class \" baseball\" -m ada"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 追蹤微調進度\n",
        "必須使用`follow`來蹤微調進度"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!openai -k \"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\" api fine_tunes.follow -i ft-NfED2Hc63L993EJVWE4XIXXI"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 列出所有微調模型\n",
        "使用`curl`來列出之前訓練過所有微調的模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!curl https://api.openai.com/v1/fine-tunes \\                                   [16:41:14]\n",
        "  -H \"Authorization: Bearer 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\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QZwlRgNcJycR"
      },
      "source": [
        "### 再輸入一次`follow`來找到模型\n",
        "`ada:ft-pytensor-2023-05-07-08-43-31`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!openai -k \"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\" api fine_tunes.follow -i ft-NfED2Hc63L993EJVWE4XIXXI"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iEjr-0iLJycR"
      },
      "source": [
        "### 查看訓練結果及驗證結果\n",
        "將訓練結果及驗證結果下載回來"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UW_9JUefJycR"
      },
      "outputs": [],
      "source": [
        "!openai -k \"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\" api fine_tunes.results -i ft-NfED2Hc63L993EJVWE4XIXXI > result.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2O3Hsqf1JycR"
      },
      "outputs": [],
      "source": [
        "results = pd.read_csv('result.csv')\n",
        "results[results['classification/accuracy'].notnull()].tail(1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "33k0h7IDJycR"
      },
      "source": [
        "### 結果為99.6%的準確率，並畫出圖型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnJydNs2JycR"
      },
      "outputs": [],
      "source": [
        "results[results['classification/accuracy'].notnull()]['classification/accuracy'].plot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kn5AICDeJycR"
      },
      "source": [
        "## 使用模型\n",
        "使用驗證集來看效果如何"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfvCsR--JycR"
      },
      "outputs": [],
      "source": [
        "test = pd.read_json('sport2_prepared_valid.jsonl', lines=True)\n",
        "test.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nuTS1PzAJycS"
      },
      "source": [
        "### 加入分隔符號\n",
        "在進行微調期間，我們需要在提示後使用相同的分隔符號。`\\n\\n###\\n\\n`。由於我們關注的是分類，我們希望`temperature`盡可能低，並且只需要一個token完成來確定模型的預測。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaBAk__ZJycS"
      },
      "outputs": [],
      "source": [
        "openai.api_key = \"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\"\n",
        "ft_model = 'ada:ft-pytensor-2023-05-07-08-43-31'\n",
        "res = openai.Completion.create(model=ft_model, prompt=test['prompt'][1] + '\\n\\n###\\n\\n', max_tokens=1, temperature=0)\n",
        "res['choices'][0]['text']\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zXgVQOo8JycS"
      },
      "source": [
        "### 可以查看log probabilities，指定completion request的logprobs參數"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Hebc0AiJycS"
      },
      "outputs": [],
      "source": [
        "res = openai.Completion.create(model=ft_model, prompt=test['prompt'][3] + '\\n\\n###\\n\\n', max_tokens=1, temperature=0, logprobs=2)\n",
        "res['choices'][0]['logprobs']['top_logprobs'][0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "TOBEBvN2JycS"
      },
      "source": [
        "### 用在新的文字上\n",
        "除了判斷電子郵件，也可以判斷推文"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-Xozf3WJycS"
      },
      "outputs": [],
      "source": [
        "sample_hockey_tweet = \"\"\"Thank you to the \n",
        "@Canes\n",
        " and all you amazing Caniacs that have been so supportive! You guys are some of the best fans in the NHL without a doubt! Really excited to start this new chapter in my career with the \n",
        "@DetroitRedWings\n",
        " !!\"\"\"\n",
        "res = openai.Completion.create(model=ft_model, prompt=sample_hockey_tweet + '\\n\\n###\\n\\n', max_tokens=1, temperature=0, logprobs=2)\n",
        "res['choices'][0]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8gTdM8IJycS"
      },
      "outputs": [],
      "source": [
        "sample_baseball_tweet=\"\"\"BREAKING: The Tampa Bay Rays are finalizing a deal to acquire slugger Nelson Cruz from the Minnesota Twins, sources tell ESPN.\"\"\"\n",
        "res = openai.Completion.create(model=ft_model, prompt=sample_baseball_tweet + '\\n\\n###\\n\\n', max_tokens=1, temperature=0, logprobs=2)\n",
        "res['choices'][0]['text']"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "3b138a8faad971cc852f62bcf00f59ea0e31721743ea2c5a866ca26adf572e75"
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
